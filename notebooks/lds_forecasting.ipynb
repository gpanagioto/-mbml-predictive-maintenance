{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a331b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6527e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro import handlers\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c072ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/processed/data_processed.csv'\n",
    "data = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4761b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290642, 42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384b15bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'machineID', 'datetime', 'voltmean_3h', 'rotatemean_3h',\n",
       "       'pressuremean_3h', 'vibrationmean_3h', 'voltsd_3h', 'rotatesd_3h',\n",
       "       'pressuresd_3h', 'vibrationsd_3h', 'voltmean_24h', 'rotatemean_24h',\n",
       "       'pressuremean_24h', 'vibrationmean_24h', 'voltsd_24h', 'rotatesd_24h',\n",
       "       'pressuresd_24h', 'vibrationsd_24h', 'error1count', 'error2count',\n",
       "       'error3count', 'error4count', 'error5count', 'comp1', 'comp2', 'comp3',\n",
       "       'comp4', 'comp1_life', 'comp2_life', 'comp3_life', 'comp4_life', 'age',\n",
       "       'model_model1', 'model_model2', 'model_model3', 'model_model4',\n",
       "       'failure', 'comp1_fail', 'comp2_fail', 'comp3_fail', 'comp4_fail'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f900340",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['datetime'] = pd.to_datetime(data.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecda2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dropna(inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1eb3e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290642, 42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ea0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_id = data.loc[data.machineID==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a9c66",
   "metadata": {},
   "source": [
    "#### Maybe do some datetime calculations to create more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc70662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = ['voltmean_3h', 'rotatemean_3h',\n",
    "       'pressuremean_3h', 'vibrationmean_3h', 'voltsd_3h', 'rotatesd_3h',\n",
    "       'pressuresd_3h', 'vibrationsd_3h', 'voltmean_24h', 'rotatemean_24h',\n",
    "       'pressuremean_24h', 'vibrationmean_24h', 'voltsd_24h', 'rotatesd_24h',\n",
    "       'pressuresd_24h', 'vibrationsd_24h', 'error1count', 'error2count',\n",
    "       'error3count', 'error4count', 'error5count','model_model1', 'model_model2', 'model_model3', 'model_model4']\n",
    "\n",
    "target_cols = ['comp1_life', 'comp2_life', 'comp3_life', 'comp4_life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c51e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_features = len(data_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46798c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = data_per_id[data_cols]\n",
    "X = X_df.values\n",
    "\n",
    "y_df = [data_per_id[target_col] for target_col in target_cols]\n",
    "y = np.array([y_df_i.values for y_df_i in y_df]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468ed8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2913, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f109b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_pc = 0.85\n",
    "train_idx = np.floor(train_size_pc*X.shape[0]).astype(int)\n",
    "\n",
    "X_train = X[:train_idx]\n",
    "X_test = X[train_idx:]\n",
    "\n",
    "y_train = y[:train_idx]\n",
    "y_test = y[train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54d4e9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(437,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "298daf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = y_train.shape[0]\n",
    "N_test = y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a53ed3",
   "metadata": {},
   "source": [
    "Try using an LDS to model the temporal dynamics of the measurements of each machine, per `machine_ID`.\n",
    "The generative process is the following:  \n",
    "$$\n",
    "process\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2505c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f2(carry, inputs):\n",
    "        \n",
    "#     u_input, noise_t = inputs\n",
    "    \n",
    "#     z_prev, betas, tau, R = carry\n",
    "            \n",
    "#     # Create the B state matrix\n",
    "#     n_states_ = len(z_prev.flatten())\n",
    "#     B = jnp.eye(n_states_)\n",
    "    \n",
    "#     # B[0] = betas\n",
    "#     B = B.at[0].set(betas)\n",
    "        \n",
    "#     z_t = jnp.dot(B, z_prev) + tau*noise_t  + jnp.dot(R, u_input) \n",
    "\n",
    "#     for i in range(len(z_prev.flatten())):\n",
    "#         # z_prev[i] = z_t[i]\n",
    "#         z_prev = z_prev.at[i].set(z_t[i])\n",
    "      \n",
    "\n",
    "#     betas = B[0]\n",
    "    \n",
    "#     print(f'betas: {betas.shape}')\n",
    "#     print(f'z_prev: {z_prev.shape}')\n",
    "#     print(f'tau: {tau.shape}')\n",
    "#     print(f\"R: {R.shape}\")\n",
    "#     print(f'z_t: {z_t.shape}')    \n",
    "#     return (betas, z_prev, tau, R), z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c0f44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_states = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8226fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(T, T_forecast, X, obs=None):\n",
    "#     \"\"\" Define priors over B, tau, noises, sigma, z_prev1 and z_prev2 (keep the shapes in mind)\n",
    "#     # Your code here\n",
    "#     \"\"\"\n",
    "    \n",
    "#     global n_states\n",
    "    \n",
    "    \n",
    "# #     beta2 = numpyro.sample(name=\"beta_2\", fn=dist.Normal(loc=0., scale=5.))\n",
    "# #     beta1 = numpyro.sample(name=\"beta_1\", fn=dist.Normal(loc=0., scale=5.))\n",
    "\n",
    "#     tau = numpyro.sample(name=\"tau\", fn=dist.HalfCauchy(scale=3.))\n",
    "    \n",
    "# #     noises = numpyro.sample(\"noises\", fn=dist.Normal(0., 1.), sample_shape=(T+T_forecast-2,))\n",
    "\n",
    "#     sigma = numpyro.sample(name=\"sigma\", fn=dist.HalfCauchy(scale=3.))\n",
    "    \n",
    "# #     z_prev1 = numpyro.sample(name=\"z_1\", fn=dist.Normal(loc=0., scale=3.))\n",
    "# #     z_prev2 = numpyro.sample(name=\"z_2\", fn=dist.Normal(loc=0., scale=3.))\n",
    "    \n",
    "#     noises = numpyro.sample(\"noises\", fn=dist.Normal(jnp.zeros(T+T_forecast-n_states),\n",
    "#                                                     jnp.ones(T+T_forecast-n_states)))\n",
    "    \n",
    "#     n, p = X.shape\n",
    "            \n",
    "#     sigma_eta = 1.\n",
    "    \n",
    "#     eta = numpyro.sample(name=\"eta\", fn=dist.Normal(loc=jnp.zeros(p), scale=jnp.ones(p)*sigma_eta))\n",
    "        \n",
    "#     scale_z = 3.\n",
    "#     z_prev = np.array([numpyro.sample(name=f\"z_prev_{i}\", fn=dist.Normal(loc=0., scale=scale_z)) for i in range(1,n_states+1)]) \n",
    "        \n",
    "#     scale_b = 5.\n",
    "#     betas = np.array([numpyro.sample(name=f\"beta_{i}\", fn=dist.Normal(loc=0., scale=scale_b)) for i in range(1,n_states+1)]) \n",
    "        \n",
    "#     \"\"\" Propagate the dynamics forward using jax.lax.scan\n",
    "#     carry = (beta1, beta2, z_prev1, z_prev2, tau)\n",
    "#     z_collection = [z_prev1, z_prev2]\n",
    "#     # Your code here\n",
    "#     \"\"\"\n",
    "    \n",
    "#     carry = (betas, z_prev, tau, eta)\n",
    "#     z_collection = jnp.array([z_prev[i] for i in range(len(z_prev.flatten()))]).reshape(1,-1)\n",
    "        \n",
    "#     carry, zs_exp = lax.scan(f2, carry, xs=[X,noises], length= T+T_forecast-n_states)\n",
    "    \n",
    "#     z_collection = jnp.concatenate((z_collection, zs_exp), axis=0)\n",
    "    \n",
    "    \n",
    "#     \"\"\" Sample the observed_y (y_obs) and predicted_y (y_pred) - note that you don't need a pyro.plate!\n",
    "#     # Your code here\n",
    "#     \"\"\"\n",
    "#     numpyro.sample(name=\"y_obs\", fn=dist.Normal(loc=z_collection[:T], scale=sigma), obs=obs[:T])    \n",
    "#     numpyro.sample(name=\"y_pred\", fn=dist.Normal(loc=z_collection[T:], scale=sigma), obs=None)\n",
    "#     return z_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03175f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(carry, inputs):\n",
    "    \n",
    "    noise_t, inpts = inputs\n",
    "    \n",
    "    beta, z_prev, tau, R = carry\n",
    "    z_t = beta*z_prev + noise_t + jnp.dot(R, inpts)\n",
    "    z_prev = z_t\n",
    "    return (beta, z_prev, tau, R), z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b9b92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(T, T_forecast, n_series=4, obs=None, inputs=None, n_previous=1):\n",
    "    \"\"\"\n",
    "    Define priors over beta, tau, sigma, z_1 (keep the shapes in mind)\n",
    "    \"\"\"\n",
    "    beta = numpyro.sample(name=\"beta\", fn=dist.Normal(loc=jnp.zeros(n_series), scale=jnp.ones(n_series)))\n",
    "    tau = numpyro.sample(name=\"tau\", fn=dist.HalfCauchy(scale=jnp.ones(n_series)))\n",
    "    sigma = numpyro.sample(name=\"sigma\", fn=dist.HalfCauchy(scale=.1))\n",
    "    z_prev = numpyro.sample(name=\"z_1\", fn=dist.Normal(loc=jnp.zeros(n_series), scale=jnp.ones(n_series)))\n",
    "    \n",
    "    n,p = inputs.shape\n",
    "    R = numpyro.sample(name=\"R\", fn=dist.Normal(loc=jnp.zeros((n_series, p)), scale=jnp.ones((n_series, p))))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Define LKJ prior\n",
    "    \"\"\"\n",
    "    L_Omega = numpyro.sample(\"L_Omega\", dist.LKJCholesky(n_series, 10.))\n",
    "    Sigma_lower = jnp.matmul(jnp.diag(jnp.sqrt(tau)), L_Omega) # lower cholesky factor of the covariance matrix\n",
    "    noises = numpyro.sample(\"noises\", fn=dist.MultivariateNormal(loc=jnp.zeros(n_series), scale_tril=Sigma_lower), sample_shape=(T+T_forecast-n_previous,))\n",
    "    \n",
    "    \"\"\"\n",
    "    Propagate the dynamics forward using jax.lax.scan\n",
    "    \"\"\"\n",
    "    carry = (beta, z_prev, tau, R)\n",
    "    z_collection = [z_prev]\n",
    "    carry, zs_exp = lax.scan(f, carry, [noises, inputs], T+T_forecast-n_previous)\n",
    "    z_collection = jnp.concatenate((jnp.array(z_collection), zs_exp), axis=0)\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(n_series):\n",
    "        numpyro.sample(name=f\"y_obs{i+1}\", fn=dist.Normal(loc=z_collection[:T, i], scale=sigma), obs=obs[:,i])\n",
    "        numpyro.sample(name=f\"y_pred{i+1}\", fn=dist.Normal(loc=z_collection[T:, i], scale=sigma), obs=None)\n",
    "        \n",
    "    return z_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c41580f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|█| 4000/4000 [04:09<00:00, 16.01it/s, 1 steps of size 5.00e-03. acc. \n"
     ]
    }
   ],
   "source": [
    "rng_key = random.PRNGKey(0)\n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "\n",
    "n_series = 4\n",
    "n_previous = 1\n",
    "T = N_train\n",
    "T_forecast = N_test\n",
    "\n",
    "\n",
    "X_t = np.concatenate([X_train[n_previous:,:], X_test], axis=0)\n",
    "\n",
    "nuts_kernel = NUTS(model=model, max_tree_depth=8, step_size=5e-3, adapt_step_size=False)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=3000, num_warmup=1000, num_chains=1)\n",
    "mcmc.run(rng_key_, T=T, T_forecast=T_forecast, n_series=n_series, inputs=X_t, obs=y_train, n_previous=n_previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7057d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameter samples\n",
    "samples_ = mcmc.get_samples()\n",
    "# nodes_ = [\"beta_1\", \"beta_2\",\"eta\", \"tau\", \"sigma\"]\n",
    "# for node in nodes_:\n",
    "#     plt.figure(figsize=(10,3))\n",
    "#     sns.displot(samples_[node], label=node)\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b30746d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_['beta'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08259b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples_['y_pred1'].mean(axis=0))\n",
    "plt.plot(y_test[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f019c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad36429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots\n",
    "f, ax = plt.subplots(5, 1)\n",
    "ax[0].plot(samples_['beta_1'])\n",
    "ax[1].plot(samples_['beta_2'])\n",
    "ax[2].plot(samples_['eta'])\n",
    "ax[3].plot(samples_['tau'])\n",
    "ax[4].plot(samples_['sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(samples):\n",
    "    \"\"\"\n",
    "    Computes the mean and standard deviation of a given sample and re-normalizes the\n",
    "    values given a certain mean and standard deviation. Returns a re-normalized vector.\n",
    "    \"\"\"\n",
    "\n",
    "    y_hat_mean = samples.mean(axis=0).reshape(-1,)\n",
    "    y_hat_std = samples.std(axis=0).reshape(-1,)\n",
    "    # y_hat_025 = (y_hat_mean - 1.96*y_hat_std) * y_std + y_mean\n",
    "    # y_hat_975 = (y_hat_mean + 1.96*y_hat_std) * y_std + y_mean\n",
    "    y_hat_renormalized = y_hat_mean\n",
    "    return y_hat_renormalized #, y_hat_025, y_hat_975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(trues, predicted):\n",
    "    \"\"\"\n",
    "    Computes the error given a vector of actual measurements against predicted. Returns\n",
    "    a list with the correlation, MAE, RAE, RMSE, and R2 between these two vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    corr = np.corrcoef(predicted, trues)[0, 1]\n",
    "    mae = np.mean(np.abs(predicted - trues))\n",
    "    rae = np.sum(np.abs(predicted - trues)) / np.sum(np.abs(trues - np.mean(trues)))\n",
    "    rmse = np.sqrt(np.mean((predicted - trues)**2))\n",
    "    r2 = max(0, 1 - np.sum((trues-predicted)**2) / np.sum((trues - np.mean(trues))**2))\n",
    "    return [corr, mae, rae, rmse, r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = compute_predictions(samples_[\"y_pred1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a220729",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error(y_test[:,0].flatten(), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4caa20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ddcce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_hat, label='$\\hat{y}$')\n",
    "plt.plot(y_test, label='y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf827d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
