{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UDjtf7V6UAPH"
      },
      "source": [
        "Import libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dp3PG_a0UAPJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd  \n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import linear_model\n",
        "import torch\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
        "from pyro.infer import MCMC, NUTS, HMC, SVI, Trace_ELBO\n",
        "from pyro.optim import Adam, ClippedAdam\n",
        "from sklearn.model_selection import train_test_split\n",
        "# fix random generator seed (for reproducibility of results)\n",
        "np.random.seed(42)\n",
        "\n",
        "# matplotlib options\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "import os\n",
        "from __init__ import root_dir, data_path, src_path\n",
        "os.path.abspath(root_dir)\n",
        "from src.models.utils import compute_error, get_data_for_component, preprocess\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUjSTdOTUAPQ",
        "outputId": "f7bf457e-f392-4071-d586-f85ca21a7948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector of (290642, 42)\n",
            "Vector of 290642 x 40\n"
          ]
        }
      ],
      "source": [
        "X_numpy = pd.read_csv(os.path.join(data_path,'processed','data_processed.csv'),parse_dates=['datetime'])\n",
        "print(\"Vector of\", X_numpy.shape)\n",
        "X_numpy = X_numpy.drop(columns=['failure','Unnamed: 0'])\n",
        "N, D = X_numpy.shape\n",
        "print(\"Vector of\", N, \"x\", D)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choose scope-target of the model and keep only the corresponding columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "life=True#flag if we want to predict lifespan or not\n",
        "if life==True:\n",
        "    X_numpy.dropna(axis=0, inplace=True)\n",
        "components = [\"comp\"+str(i)+\"_life\" for i in range(1,5)]\n",
        "X0 = get_data_for_component(X_numpy, components[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "machineID            0\n",
              "datetime             0\n",
              "voltmean_3h          0\n",
              "rotatemean_3h        0\n",
              "pressuremean_3h      0\n",
              "vibrationmean_3h     0\n",
              "voltsd_3h            0\n",
              "rotatesd_3h          0\n",
              "pressuresd_3h        0\n",
              "vibrationsd_3h       0\n",
              "voltmean_24h         0\n",
              "rotatemean_24h       0\n",
              "pressuremean_24h     0\n",
              "vibrationmean_24h    0\n",
              "voltsd_24h           0\n",
              "rotatesd_24h         0\n",
              "pressuresd_24h       0\n",
              "vibrationsd_24h      0\n",
              "error1count          0\n",
              "error2count          0\n",
              "error3count          0\n",
              "error4count          0\n",
              "error5count          0\n",
              "comp1                0\n",
              "comp2                0\n",
              "comp3                0\n",
              "comp4                0\n",
              "comp1_life           0\n",
              "comp2_life           0\n",
              "comp3_life           0\n",
              "comp4_life           0\n",
              "age                  0\n",
              "model_model1         0\n",
              "model_model2         0\n",
              "model_model3         0\n",
              "model_model4         0\n",
              "comp1_fail           0\n",
              "comp2_fail           0\n",
              "comp3_fail           0\n",
              "comp4_fail           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_numpy.isna().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split and std data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SgAeX4vUAPV",
        "outputId": "803d4fe8-2f8f-4964-b98b-595d56d4ba42"
      },
      "outputs": [],
      "source": [
        "\n",
        "y, X, X_train_torch, y_train_torch,X_test_torch, X_test, y_test, X_train, y_train, y_std, y_mean=preprocess(X0.copy(),0.1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define models, train and test them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['voltmean_3h', 'rotatemean_3h', 'pressuremean_3h', 'vibrationmean_3h',\n",
              "       'voltsd_3h', 'rotatesd_3h', 'pressuresd_3h', 'vibrationsd_3h',\n",
              "       'voltmean_24h', 'rotatemean_24h', 'pressuremean_24h',\n",
              "       'vibrationmean_24h', 'voltsd_24h', 'rotatesd_24h', 'pressuresd_24h',\n",
              "       'vibrationsd_24h', 'error1count', 'error2count', 'error3count',\n",
              "       'error4count', 'error5count', 'age', 'model_model1', 'model_model2',\n",
              "       'model_model3', 'model_model4', 'comp1_life'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X0.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imd8iv_VUAPj",
        "outputId": "03068511-9d9a-4473-98b4-29083ef5ec1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.3775880e-02  1.0716524e-03 -1.2307315e-03  1.6640450e-03\n",
            " -8.6010143e-04 -2.8204415e-03  2.6229597e-04  3.7947111e-04\n",
            " -2.5117554e-02 -2.6605227e-03  2.5870181e-03  1.1132961e-03\n",
            " -5.3956159e-03 -8.7619363e-04 -1.6128893e-03  5.7711871e-03\n",
            " -3.4052096e-02 -3.7997090e-03  6.0530035e-03 -2.7326681e-04\n",
            "  7.5445324e-03  1.5423427e-02  3.1862695e+02  3.1900397e+02\n",
            "  4.0285294e+02  3.8920804e+02]\n",
            "MAE: 0.7432485469172565\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets, linear_model\n",
        "\n",
        "regr = linear_model.LinearRegression(fit_intercept=False)\n",
        "regr.fit(X_train_torch, y_train_torch)\n",
        "preds_lr = regr.predict(X_test_torch)\n",
        "print(regr.coef_)\n",
        "\n",
        "mae = np.mean(np.abs(y_test-preds_lr))\n",
        "print(\"MAE:\", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c2UJdc8UAPm",
        "outputId": "b73a4717-1849-46e3-fce7-45e7514b32d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EVCbGSo3UAPp"
      },
      "source": [
        "A bit high given the range of the $y$ values...\n",
        "\n",
        "Perhaps we can get a better intuition about the quality of the predictions of the linear regression model if we try to visualize them:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G0ezDpSXUAPy"
      },
      "source": [
        "## Neural Network model in Pyro"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3MKF8NOeUAPz"
      },
      "source": [
        "As mentioned in the lecture's slides, we can obtain complex non-linear function of the inputs by making use of Neural Networks! The following code implements a multi-layer fully-connected NNet in Pyro. Note that, since Pyro is built on top of PyTorch, it is very well suited for building Bayesian Neural Networks and combining them with larger, more complex probabilistic graphical models. This is not the case for STAN! \n",
        "\n",
        "We begin by defining the neural network as a `PyroModule` instead of a PyTorch module (i.e. a class that extends ```torch.nn.Module```), as it is customary when using PyTorch for implementing deep neural networks. `PyroModule` is a subclass of `nn.Module`, which allows us to Pyro-ize an existing class (e.g. `linear_layer = PyroModule[nn.Linear](in_dim, out_dim))`) and utilize modules already created in PyTorch. Additionally, priors are placed on the weights by using `PyroSample` as illustrated below. Every neural network in PyTorch has a  `forward` function, that - implementation wise - closely resembles how you coded up Pyro models in last week's notebook."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure that you understand the code above and don't hesitate to ask for clarifications! :-)\n",
        "\n",
        "We can now perform Bayesian inference in this model (in this case using SVI) to compute the posterior distributions over the neural net weights, as we would normally do for other Pyro models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqSviplh7_r4",
        "outputId": "63159463-8de4-4c7c-ca83-e28f538ac62e"
      },
      "outputs": [],
      "source": [
        "# Define guide function\n",
        "from src.models.train_model import train_nn\n",
        "\n",
        "model_FFNN,guide=train_nn(\"modelFFNN\", X_train_torch, y_train_torch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define guide function\n",
        "from src.models.train_model import train_nn\n",
        "\n",
        "model_RNN,guide=train_nn(\"modelRNN\", X_train_torch, y_train_torch)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iCQS7u6TCGEw"
      },
      "source": [
        "After convergence, we can make predictions for the test set by again leveraging the ```Predictive``` class provided by Pyro:\n",
        "Let's now calculate the MAE and compare it with the linear regression model from above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBQuagLB7z_I",
        "outputId": "5de86b26-0b16-4b67-894e-18fa0efcfe05"
      },
      "outputs": [],
      "source": [
        "from src.models.test_model import test_nn, test_nn_beta, mae_test, plot_pred\n",
        "\n",
        "y_pred=test_nn(model_FFNN,guide,X_test_torch)\n",
        "\n",
        "mae_test(y_pred,y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-dd6vTjUAP3"
      },
      "source": [
        "We can observe that using the Pyro model above, we were able to fit a Neural Network to our non-linear dataset, and that resulted in a much lower error. For many problems where one cares only about the prediction error this could be the end of the story. However, we will do something different here.\n",
        "\n",
        "Assume that we are actually interested in investigating how $x_1$ affects $y$ (e.g., imagine $y$ is the price of a house and $x_1$ is the square footage), but not so much about the effect of $x_2$. You could use a NNet to model the relationship of $y$ with both $x_1$ and $x_2$, however, NNets are black-boxes that are pretty hard to interpret. So, we are at a crossroads: we can either have a simple linear model (interpretable!) or a complex neural network (black-box). But can we combine both?? :-)\n",
        "\n",
        "In order to analyse the effect of $x_1$ of $y$, we will explore the combination of PGMs and (Bayesian) Neural Networks! To do so, we will a assume a model of the following form:\n",
        "\n",
        "\\begin{align}\n",
        "y = \\beta \\, x_1 + \\mbox{NNet}(x_2) + \\epsilon\n",
        "\\end{align}\n",
        "\n",
        "In other words, we use a simple linear regression for modelling the relationship with $x_1$, and a Bayesian neural network for $x_2$.\n",
        "\n",
        "Can you modify the Pyro code of the neural network above in order to implement this variation of the model?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DnOr4nmmHzav"
      },
      "source": [
        "Once you finished implementing the model above, run inference on it using SVI:\n",
        "\n",
        "\n",
        "Change x1 in the model's class to something that has the highest lr weight!!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzipe6vqDqN5",
        "outputId": "3ff1c569-6127-42a4-8833-1d45724905d2"
      },
      "outputs": [],
      "source": [
        "# Define guide function\n",
        "from src.models.train_model import train_nn\n",
        "# Define guide function\n",
        "\n",
        "model_FFNN_interpretable,guide=train_nn(\"modelFFNN_interpretable\", X_train_torch, y_train_torch)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KEFyvcBAINOh"
      },
      "source": [
        "Let us now have a look at the estimated value for the coefficient $\\beta$ over the input dimension $x_1$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-ZskdzyHvsc",
        "outputId": "6a214513-78f6-416f-f1fc-8ca208c74d80"
      },
      "outputs": [],
      "source": [
        "test_nn_beta(model_FFNN_interpretable,guide,X_test_torch)\n",
        "\n",
        "y_pred=test_nn(model_FFNN_interpretable,guide,X_test_torch)\n",
        "\n",
        "mae_test(y_pred,y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V71bz8NIUAQJ"
      },
      "source": [
        "Unlike with the linear regression model, we managed to recover the true value of $\\beta$ that was used to generate the data ($\\beta=2$)!!\n",
        "\n",
        "What can we conclude from this? It seems that modelling more accuratly the relationship between $x_2$ and $y$ with the NNet, takes away some of the \"burden\" from the linear part of the model, which can then focus on modelling the effect of $x_1$ better! Makes sense, right?\n",
        "\n",
        "But that is only part of the \"story\". Let us now look at the predictions for the testset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "y_true,y_pre=plot_pred(y_pred,y_test,y_std,y_mean,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr, mae, rae, rmse, r2, yy_true, ppreds = compute_error(y_true, y_pre, None)\n",
        "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))\n",
        "\n",
        "corr, mae, rae, rmse, r2, yy_true, ppreds = compute_error(y_true, y_pre, 60)\n",
        "print(\"CorrCoef: %.3f\\nMAE: %.3f\\nRMSE: %.3f\\nR2: %.3f\" % (corr, mae, rmse, r2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6fLHUiC-UAQQ"
      },
      "source": [
        "Uau! That is quite a dramatic reduction in prediction error when compared to the simple linear regression model, and we still managed to keep the interpretability over the effect of $x_1$!!\n",
        "\n",
        "Let's see if visually we can draw a similar conclusion:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CNahGT6iUAQT"
      },
      "source": [
        "We can see that the composite model (Linear PGM + NNet) predicts almost perfectly the target variable $y$ for the testset! Notice that it managed to capture both the linear trend over the $x_1$ dimension and the complex non-linear trend on the $x_2$ dimension (the one that resulted from the sine function...).\n",
        "\n",
        "A few more visualizations to analyse the quality of the predictions of the composite model (Linear PGM + NNet) in comparison with the predictions of the linear regression model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(X_test[:,0], y_test, \"rx\")\n",
        "plt.plot(X_test[:,0], preds_lr, 'yo')\n",
        "plt.plot(X_test[:,0], y_pred, 'bo')\n",
        "plt.legend([\"true (noisy) data points\", \"linear regression\", \"NNet predictions SVI\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Gb-8VQ3RUAQW",
        "outputId": "f1c7ae8d-bcb9-42c7-e983-d51a354e4abb",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "plt.plot(X_test[:,1], y_test, \"rx\")\n",
        "plt.plot(X_test[:,1], preds_lr, 'yo')\n",
        "plt.plot(X_test[:,1], y_pred, 'bo')\n",
        "plt.legend([\"true (noisy) data points\", \"linear regression\", \"NNet predictions SVI\"])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "05 - Neural Network + Linear PGM - Pyro - solutions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mbml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5b26c03c8c097a486b5e8d755760710705bdc4f3115effbeda73240220beb13b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
