{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7028648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro import handlers\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410ba016",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/processed/data_processed.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Use data only for specific machineID\n",
    "machine_id = 1\n",
    "data_1 = data.loc[data.machineID==machine_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c405b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32069/777938672.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1['datetime'] = pd.to_datetime(data_1.datetime)\n"
     ]
    }
   ],
   "source": [
    "# Change type of datetime column to datetime (the object type)\n",
    "data_1['datetime'] = pd.to_datetime(data_1.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "898a7c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32069/665843931.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1.drop(['Unnamed: 0'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop the previously used index column named Unnamed: 0\n",
    "data_1.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e0b4c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['machineID', 'datetime', 'voltmean_3h', 'rotatemean_3h',\n",
       "       'pressuremean_3h', 'vibrationmean_3h', 'voltsd_3h', 'rotatesd_3h',\n",
       "       'pressuresd_3h', 'vibrationsd_3h', 'voltmean_24h', 'rotatemean_24h',\n",
       "       'pressuremean_24h', 'vibrationmean_24h', 'voltsd_24h', 'rotatesd_24h',\n",
       "       'pressuresd_24h', 'vibrationsd_24h', 'error1count', 'error2count',\n",
       "       'error3count', 'error4count', 'error5count', 'comp1', 'comp2', 'comp3',\n",
       "       'comp4', 'comp1_life', 'comp2_life', 'comp3_life', 'comp4_life', 'age',\n",
       "       'model_model1', 'model_model2', 'model_model3', 'model_model4',\n",
       "       'failure', 'comp1_fail', 'comp2_fail', 'comp3_fail', 'comp4_fail'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef7910",
   "metadata": {},
   "source": [
    "We can also create 2 new features, the $sin$ and $cos$ of the (also created) hour feature.  \n",
    "\n",
    "For now, in the testing, I will use the telemetry and error count data and have as output ($y$) a specific component's remaining life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "507e393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['voltmean_3h', 'rotatemean_3h',\n",
    "       'pressuremean_3h', 'vibrationmean_3h', 'voltsd_3h', 'rotatesd_3h',\n",
    "       'pressuresd_3h', 'vibrationsd_3h', 'voltmean_24h', 'rotatemean_24h',\n",
    "       'pressuremean_24h', 'vibrationmean_24h', 'voltsd_24h', 'rotatesd_24h',\n",
    "       'pressuresd_24h', 'vibrationsd_24h', 'error1count', 'error2count',\n",
    "       'error3count', 'error4count', 'error5count','model_model1', 'model_model2', 'model_model3', 'model_model4']\n",
    "\n",
    "output_columns = ['comp1_life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c354077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = data_1[input_columns]\n",
    "y_df = data_1[output_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3abeeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.values\n",
    "y = y_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f19919",
   "metadata": {},
   "source": [
    "It is not a good idea to randomly split the dataset to train and split, because the temporal model relies on the continuity of the input data. As a result, the split is performed as taking the first $n$ percent of the available data as training set, while the rest is used as a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b4259cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc = 0.8 # percentage of data used as training set\n",
    "\n",
    "X_train = X[:int(train_perc*X.shape[0])]\n",
    "y_train = y[:int(train_perc*X.shape[0])]\n",
    "\n",
    "X_test = X[int(train_perc*X.shape[0]):]\n",
    "y_test = y[int(train_perc*X.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ab005ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, p = X_train.shape\n",
    "n_test, _ = X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf342a19",
   "metadata": {},
   "source": [
    "Create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8cb9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(carry, noise_t):\n",
    "    beta, z_prev, tau = carry\n",
    "    z_t = beta*z_prev + noise_t\n",
    "    z_prev = z_t\n",
    "    return (beta, z_prev, tau), z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e963aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(T, T_forecast, obs1=None, ix_mis1=None, ix_obs1=None, obs2=None, ix_mis2=None, ix_obs2=None):\n",
    "    \"\"\"\n",
    "    Define priors over beta, tau, sigma, z_1 (keep the shapes in mind)\n",
    "    \"\"\"\n",
    "    beta = numpyro.sample(name=\"beta\", fn=dist.Normal(loc=jnp.zeros(2), scale=jnp.ones(2)))\n",
    "    tau = numpyro.sample(name=\"tau\", fn=dist.HalfCauchy(scale=jnp.ones(2)))\n",
    "    sigma = numpyro.sample(name=\"sigma\", fn=dist.HalfCauchy(scale=.1))\n",
    "    z_prev = numpyro.sample(name=\"z_1\", fn=dist.Normal(loc=jnp.zeros(2), scale=jnp.ones(2)))\n",
    "    \n",
    "    \"\"\"\n",
    "    Define LKJ prior\n",
    "    \"\"\"\n",
    "    L_Omega = numpyro.sample(\"L_Omega\", dist.LKJCholesky(2, 10.))\n",
    "    Sigma_lower = jnp.matmul(jnp.diag(jnp.sqrt(tau)), L_Omega) # lower cholesky factor of the covariance matrix\n",
    "    noises = numpyro.sample(\"noises\", fn=dist.MultivariateNormal(loc=jnp.zeros(2), scale_tril=Sigma_lower), sample_shape=(T+T_forecast-1,))\n",
    "    \n",
    "    \"\"\"\n",
    "    Propagate the dynamics forward using jax.lax.scan\n",
    "    \"\"\"\n",
    "    carry = (beta, z_prev, tau)\n",
    "    z_collection = [z_prev]\n",
    "    carry, zs_exp = lax.scan(f, carry, noises, T+T_forecast-1)\n",
    "    z_collection = jnp.concatenate((jnp.array(z_collection), zs_exp), axis=0)\n",
    "    \n",
    "    \"\"\"\n",
    "    Sample the observed y (y_obs) and missing y (y_mis)\n",
    "    \"\"\"\n",
    "    numpyro.sample(name=\"y_mis1\", fn=dist.Normal(loc=z_collection[ix_mis1, 0], scale=sigma), obs=None)\n",
    "    numpyro.sample(name=\"y_obs1\", fn=dist.Normal(loc=z_collection[ix_obs1, 0], scale=sigma), obs=obs1)\n",
    "    numpyro.sample(name=\"y_mis2\", fn=dist.Normal(loc=z_collection[ix_mis2, 1], scale=sigma), obs=None)\n",
    "    numpyro.sample(name=\"y_obs2\", fn=dist.Normal(loc=z_collection[ix_obs2, 1], scale=sigma), obs=obs2)\n",
    "    return z_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "add63390",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m nuts_kernel \u001b[38;5;241m=\u001b[39m NUTS(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      5\u001b[0m mcmc \u001b[38;5;241m=\u001b[39m MCMC(nuts_kernel, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, num_warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, num_chains\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m mcmc\u001b[38;5;241m.\u001b[39mrun(rng_key_, T\u001b[38;5;241m=\u001b[39m\u001b[43mN\u001b[49m, T_forecast\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, obs1\u001b[38;5;241m=\u001b[39my_obs1, ix_mis1\u001b[38;5;241m=\u001b[39mix_mis1, ix_obs1\u001b[38;5;241m=\u001b[39mix_obs1, \n\u001b[1;32m      7\u001b[0m          obs2\u001b[38;5;241m=\u001b[39my_obs2, ix_mis2\u001b[38;5;241m=\u001b[39mix_mis2, ix_obs2\u001b[38;5;241m=\u001b[39mix_obs2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "rng_key = random.PRNGKey(0)\n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "\n",
    "nuts_kernel = NUTS(model=model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, num_warmup=1000, num_chains=1)\n",
    "mcmc.run(rng_key_, T=N, T_forecast=0, obs1=y_obs1, ix_mis1=ix_mis1, ix_obs1=ix_obs1, \n",
    "         obs2=y_obs2, ix_mis2=ix_mis2, ix_obs2=ix_obs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c44d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
